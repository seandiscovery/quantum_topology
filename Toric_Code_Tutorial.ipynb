{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquil import Program\n",
    "from pyquil.gates import *\n",
    "from pyquil.quil import address_qubits\n",
    "from pyquil.quilatom import QubitPlaceholder\n",
    "from pyquil.api import QVMConnection\n",
    "from pyquil.api import WavefunctionSimulator\n",
    "\n",
    "import networkx as nx \n",
    "from toric_code import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toric Code Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello there! This notebook explains the basic concepts of our implementation of the toric code, which is described in detail in our final paper. We'll discuss how to use the code, and also the major problems we've run into in determining the error threshold. This notebook assumes that you've installed the latest release of ``PyQuil``, ``Numpy``, and ``NetworkX``. \n",
    "\n",
    "To begin, let's construct the primal, dual, and distance graphs for a specified lattice size $L$. We'll pick $L = 3$ for simplicity here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "primal, dual, distance = construct_toric_code(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``construct_toric_code`` returns ``NetworkX`` graph structures. For details, see the ``NetworkX`` documentation, but note that we can access the edges and nodes of the primal and dual graphs as necessary. Each edge contains a ``QubitPlaceholder`` object representing a data qubit, while each vertex contains a ``QubitPlaceholder`` object representing the $X$ stabilizers (on the primal graph) or $Z$ stabilizers (on the dual graph). \n",
    "\n",
    "The next step in our protocl is to initialize the qubits to $+1$ eigenstates of the $X$ stabilizers and $Z$ stabilizers. Unfortunately, this has proven to be the major limiting factor in our experiment, as constructing this initial state is highly non-trivial. We've attempted to follow the method described in Dennis et al. (http://info.phys.unm.edu/~alandahl/papers/jmp43_4452.pdf?fbclid=IwAR3XnFXFsdVkoUs9iCp0oA-ssHtflBFpPubNwNZxQ_BNvmjcCldh0xhd7mg), which involves the following steps: \n",
    "\n",
    "1) Initialize the qubits to the state $|0\\rangle^{\\otimes n}$, where $n$ is the number of physical qubits. \n",
    "\n",
    "2) Without applying any errors, run the $X$ syndrome extraction protocol, which involves the circuit shown in Figure 1 of our final paper. \n",
    "\n",
    "3) After the $X$ syndrome extraction, about half of our ancilla qubits are expected to be in the $|1\\rangle$ state, which corresponds to a measured error (that is, a $-1$ eigenvalue upon measuring the $X$ stabilizer). Construct an arbitrary one-chain with these error nodes on the boundaries (in this case, a \"one-chain\" is simply a collection of edges between vertices in the graph; note that these edges do not have to form one continuous path). Then apply a $Z$ operator to the data qubit on each edge of this one-chain. \n",
    "\n",
    "After this procedure, the data qubits of the toric code are in a $+1$ eigenstate of the stabilizer operators. We started an implementation of this initialization procedure in the function ``initialize_toric_code`` below. Unfortunately, we haven't yet figured out a good algorithm for generating a one-chain that has error nodes as a boundary. We're currently working on this problem, but it's been a lot more difficult than we were expecting! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_toric_code(primal, dual, L): \n",
    "    primal_intial = Program() \n",
    "    faulty_nodes = syndrome_extraction(primal, L, primal_initial, \"X\")\n",
    "    # faulty_nodes returns a list of the nodes with errors \n",
    "    # At this point, we construct a one-chain with these error nodes as \n",
    "    # a boundary\n",
    "    # TODO: Get this algorithm working \n",
    "    return primal_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``syndrome_extraction`` above is one of the most important functions of our code. Given a graph (primal or dual) and a stabilizer operator, it measures the stabilizer operator and returns a list of nodes (ancilla qubits) that returned the $|1\\rangle$ state (a $-1$ eigenvalue, indicating an error). \n",
    "\n",
    "After initializing the toric code, we can begin a simulation of the toric code, which is given in our ``main`` function. The first step of the simulation is to apply errors to the code under the independent noise assumption (see our paper for further details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z {q43451957320}\n",
      "Z {q43452624968}\n",
      "Z {q43452625248}\n",
      "\n",
      "X {q43452625080}\n",
      "X {q43451957544}\n",
      "X {q43451957600}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the data qubits are correctly initialized, we need to simulate an error \n",
    "# Working under the independent noise assumption; note that we must set a p value \n",
    "primal_pq, phase_flips, dual_pq, bit_flips = simulate_error(primal, dual, p=0.2)\n",
    "print(primal_pq) # Operators for random phase flips\n",
    "print(dual_pq) # Operators for random bit flips "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``simulate_error`` returns programs for the primal and dual graphs representing the bit/phase flip operations, as well as lists of edges representing where bit/phase flips were applied. Now, we need to run the ``syndrome_extraction`` algorithm for each graph to determine where bit and phase flips occured. Note that this is the same function used in ``initialize_toric_code`` above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1), (1, 2), (2, 1), (2, 2)]\n",
      "[(0, 1), (1, 0), (1, 1), (1, 2), (2, 1), (2, 2)]\n"
     ]
    }
   ],
   "source": [
    "faulty_primal_nodes = syndrome_extraction(primal, L, primal_pq, \"X\") # Extraction for X stabilizers on primal graph \n",
    "faulty_dual_nodes = syndrome_extraction(dual, L, dual_pq, \"Z\") # Extraction for Z stabilizers on dual graph \n",
    "print(faulty_primal_nodes)\n",
    "print(faulty_dual_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've identified where the errors are, we need to correct them. For this, we use the minimum-weight perfect-matching algorithm (MWPM), as described in our final report. This algorithm is implemented (using ``NetworkX``, with a few modifications) in our code as ``mwpm``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ebfa003355d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprimal_correction_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmwpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaulty_primal_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Corrections for primal graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdual_correction_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmwpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaulty_dual_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Corrections for dual graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stanford_2018_2019/cs_269q/final_project/toric_code.py\u001b[0m in \u001b[0;36mmwpm\u001b[0;34m(G, distance_G, L, errors)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mmatching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_weight_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmwpm_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxcardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_perfect_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmwpm_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0mcorrection_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0medge\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatching\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrection_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "primal_correction_paths = mwpm(primal, distance, L, faulty_primal_nodes) # Corrections for primal graph \n",
    "dual_correction_paths = mwpm(dual, distance, L, faulty_dual_nodes) # Corrections for dual graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE an important point here: a perfect matching is not always possible, given the errors we applied! In particular, if an odd number of errors occur, we cannot generate a perfect matching to identify a correction path for the code. In this case, we're raising an ``AssertionError`` because a perfect matching is not possible, which is expected because our qubits were not initialized correctly. \n",
    "\n",
    "To correct for the indicated errors, we use the ``apply_operation`` function. Given a correction path and correction operator, this function walks along the path and applies the correction operator to each data qubit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primal_correct_pq = apply_operation(primal_correction_paths, primal, Z)\n",
    "dual_correct_pq = apply_operation(dual_correction_paths, dual, X)\n",
    "# We won't run this cell, since the mwpm algorithm failed and thus the correction paths \n",
    "# do not exist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we just run the correction programs \n",
    "qvm = QVMConnection() \n",
    "qvm.run(primal_correct_pq)\n",
    "qvm.run(dual_correct_pq)\n",
    "# Again, we won't run this cell becuase of the mwpm algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes one complete cycle of our simulation. To compute the error threshold, we simply repeat this process while varying $L$ and $p$, and measure the average quantum state lifetime as a function of these parameters. Due to our issues with initialization, we unfortunately haven't been able to get this computation to work, but we plan to implement it once we solve our initialization problem (this unfortuntately might occur too late for it to impact our grade at all... but alas, such is the risk of pursuing the toric code in a final project!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
